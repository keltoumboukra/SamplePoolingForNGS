{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "b6df1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import PySimpleGUI as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "8d37fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp \n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "d9a96e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_file_folder = \"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/ClariostarOutputs/\"\n",
    "input_file_name = \"qubit_data_Marko_22112022.CSV\"\n",
    "\n",
    "# final desired vol (nL)\n",
    "final_pool_vol = 10000\n",
    "\n",
    "# well position of pool in output plate\n",
    "pool_well_in_output_plate = \"A1\"\n",
    "\n",
    "# minimum volume to be pipetted (nL)\n",
    "min_pipetting_capacity = float(25) # for Echo\n",
    "\n",
    "# minimum volume that can be pipetted \n",
    "vol_available_in_well = 10000 # for e.g, if there is 20 uL in the well, 5000 nL is what can be available as 15 uL is the minimum working range in the PP-0200 Echo plate)\n",
    "\n",
    "# Beckman or Echo\n",
    "BeckmanOrEcho = \"Echo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "52a60e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask user which platform to use: Beckman or Echo\n",
    "\n",
    "sg.theme('LightBrown9')\n",
    "    \n",
    "layout = [\n",
    "        [sg.Text('Choose automated platform to use:\\n\\t- Echo: non genomic DNA\\n\\t- Beckman: genomic DNA')],\n",
    "        [sg.Text('Desired platform name (\"Echo\" or \"Beckman\"):')],\n",
    "        [sg.InputText(\"Echo\")],\n",
    "        [sg.Submit(), sg.Cancel()]\n",
    "        ]\n",
    "\n",
    "window = sg.Window('NGS Pooling', layout)\n",
    "event, values = window.read()\n",
    "window.maximize()\n",
    "window.close()\n",
    "\n",
    "BeckmanOrEcho = values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "647ecb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GUI\n",
    "\n",
    "sg.theme('LightBrown9')\n",
    "\n",
    "\n",
    "if BeckmanOrEcho == \"Echo\":\n",
    "    layout = [\n",
    "        [sg.Text('Please enter the desired parameters')],\n",
    "        [sg.Text('Input file folder (ending with /)', size =(25, 1)), sg.InputText(\"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/ClariostarOutputs/\")],\n",
    "        [sg.Text('Input file name', size =(25, 1)), sg.InputText(\"qubit_data_Marko_22112022.CSV\")],\n",
    "        [sg.Text('Output file folder (ending with /)', size =(25, 1)), sg.InputText(\"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\")],\n",
    "        [sg.Text('Final pool volume (nL)', size =(25, 1)), sg.InputText(\"1000\")],\n",
    "        [sg.Text('Pooling well position', size =(25, 1)), sg.InputText(\"A1\")],\n",
    "        [sg.Text('Minimum pipetting capacity (nL)', size =(25, 1)), sg.InputText(\"25\")],\n",
    "        [sg.Text('Sample volume available (nL)', size =(25, 1)), sg.InputText(\"5000\")],\n",
    "        [sg.Submit(), sg.Cancel()]\n",
    "    ]\n",
    "\n",
    "elif BeckmanOrEcho == \"Beckman\":\n",
    "    layout = [\n",
    "        [sg.Text('Please enter the desired parameters')],\n",
    "        [sg.Text('Input file folder (ending with /)', size =(25, 1)), sg.InputText(\"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/ClariostarOutputs/\")],\n",
    "        [sg.Text('Input file name', size =(25, 1)), sg.InputText(\"qubit_data_Marko_22112022.CSV\")],\n",
    "        [sg.Text('Output file folder (ending with /)', size =(25, 1)), sg.InputText(\"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\")],\n",
    "        [sg.Text('Final pool volume (uL)', size =(25, 1)), sg.InputText(\"10\")],\n",
    "        [sg.Text('Pooling well position', size =(25, 1)), sg.InputText(\"A1\")],\n",
    "        [sg.Text('Minimum pipetting capacity (uL)', size =(25, 1)), sg.InputText(\"0.5\")],\n",
    "        [sg.Text('Sample volume available (uL)', size =(25, 1)), sg.InputText(\"25\")],\n",
    "        [sg.Submit(), sg.Cancel()]\n",
    "    ]\n",
    "\n",
    "window = sg.Window('Robot File Generator For NGS Pooling', layout)\n",
    "event, values = window.read()\n",
    "window.maximize()\n",
    "window.close()    \n",
    "\n",
    "# Assigning values \n",
    "input_file_folder = values[0]\n",
    "input_file_name = values[1]\n",
    "output_files_folder = values[2]\n",
    "final_pool_vol = float(values[3])\n",
    "pool_well_in_output_plate = values[4]\n",
    "min_pipetting_capacity = float(values[5])\n",
    "vol_available_in_well = float(values[6])\n",
    "\n",
    "# Dataframes\n",
    "input_file_df = pd.read_csv(input_file_folder + input_file_name)\n",
    "input_file_df.rename(columns={input_file_df.columns[2]: \"Concentration\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "855698a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/NGSpooling_20230110-123903/InputFiles/InputFile.csv'"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "\n",
    "output_files_folder = output_files_folder + \"NGSpooling_\" + timestr\n",
    "os.mkdir(output_files_folder)\n",
    "output_files_folder = output_files_folder + \"/\"\n",
    "\n",
    "output_file_name = \"ProcessingDetails.csv\"\n",
    "output_file_df = pd.DataFrame(columns=['Sample Well ID','Sample Concentration','Sample Calculated Weight', 'Sample Calculated Weight Normalised', 'Sample Calculated Volume In Pool'])\n",
    "\n",
    "if BeckmanOrEcho == \"Echo\":\n",
    "    output_echo_file_name = \"EchoFile.csv\"\n",
    "    output_echo_file_df = pd.DataFrame(columns=['Source Well','Destination Well','Transfer Volume'])\n",
    "elif BeckmanOrEcho == \"Beckman\":\n",
    "    output_beckman_file_name = \"BeckmanFile.csv\"\n",
    "    output_beckman_file_df = pd.DataFrame(columns=['Source Well','Destination Well','Transfer Volume'])    \n",
    "\n",
    "output_report_name = \"ExceptionsReport.csv\"\n",
    "output_report_df = pd.DataFrame(columns=['Sample Well ID','Sample Concentration','Comment'])\n",
    "\n",
    "# Copy input file into the output folder\n",
    "os.mkdir(output_files_folder + \"InputFiles/\")\n",
    "shutil.copyfile(input_file_folder+input_file_name, output_files_folder + \"InputFiles/\" + \"InputFile.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "7eb00515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A01 48.739\n",
      "1 A03 6.8420000000000005\n",
      "2 A05 -0.868\n",
      "3 A07 -0.833\n",
      "4 A09 -0.887\n",
      "5 A11 -0.838\n",
      "6 A13 -0.8240000000000001\n",
      "7 A15 -0.775\n",
      "8 A17 -0.83\n",
      "9 A19 -0.8690000000000001\n",
      "10 A21 -0.797\n",
      "11 A23 -0.6659999999999999\n",
      "12 C01 24.495\n",
      "13 C03 3.7319999999999998\n",
      "14 C05 -0.8959999999999999\n",
      "15 C07 -0.94\n",
      "16 C09 -0.981\n",
      "17 C11 -0.9640000000000001\n",
      "18 C13 -0.8490000000000001\n",
      "19 C15 -0.892\n",
      "20 C17 -0.8370000000000001\n",
      "21 C19 -0.88\n",
      "22 C21 -0.88\n",
      "23 C23 -0.85\n",
      "24 E01 14.040999999999999\n",
      "25 E03 50.621\n",
      "26 E05 -1.003\n",
      "27 E07 -0.8959999999999999\n",
      "28 E09 -1.062\n",
      "29 E11 -0.927\n",
      "30 E13 -0.8859999999999999\n",
      "31 E15 -1.0170000000000001\n",
      "32 E17 -0.985\n",
      "33 E19 -0.9329999999999999\n",
      "34 E21 -0.868\n",
      "35 E23 -0.863\n",
      "36 G01 6.997000000000001\n",
      "37 G03 25.445999999999998\n",
      "38 G05 -0.885\n",
      "39 G07 -0.89\n",
      "40 G09 -0.9520000000000001\n",
      "41 G11 -0.879\n",
      "42 G13 -0.9570000000000001\n",
      "43 G15 -0.917\n",
      "44 G17 -0.877\n",
      "45 G19 -0.833\n",
      "46 G21 -0.802\n",
      "47 G23 -0.57\n",
      "48 I01 3.778\n",
      "49 I03 12.245\n",
      "50 I05 -0.8440000000000001\n",
      "51 I07 -0.95\n",
      "52 I09 -0.828\n",
      "53 I11 -0.8270000000000001\n",
      "54 I13 -0.713\n",
      "55 I15 -0.905\n",
      "56 I17 -0.915\n",
      "57 I19 -0.8290000000000001\n",
      "58 I21 -0.557\n",
      "59 I23 -0.721\n",
      "60 K01 48.1\n",
      "61 K03 6.396\n",
      "62 K05 -0.831\n",
      "63 K07 -0.828\n",
      "64 K09 -0.878\n",
      "65 K11 -0.868\n",
      "66 K13 -0.917\n",
      "67 K15 -0.8240000000000001\n",
      "68 K17 -0.711\n",
      "69 K19 -0.7909999999999999\n",
      "70 K21 -0.7979999999999999\n",
      "71 K23 -0.648\n",
      "72 M01 24.328000000000003\n",
      "73 M03 3.03\n",
      "74 M05 -0.759\n",
      "75 M07 -0.695\n",
      "76 M09 -0.816\n",
      "77 M11 -0.8079999999999999\n",
      "78 M13 -0.759\n",
      "79 M15 -0.7170000000000001\n",
      "80 M17 -0.708\n",
      "81 M19 -0.79\n",
      "82 M21 -0.669\n",
      "83 M23 -0.67\n",
      "84 O01 12.352\n",
      "85 O05 -0.58\n",
      "86 O07 -0.6970000000000001\n",
      "87 O09 -0.636\n",
      "88 O11 -0.685\n",
      "89 O13 -0.6990000000000001\n",
      "90 O15 -0.5870000000000001\n",
      "91 O17 -0.642\n",
      "92 O19 -0.66\n",
      "93 O21 -0.705\n",
      "94 O23 -0.6679999999999999\n"
     ]
    }
   ],
   "source": [
    "# Trim input data frame \n",
    "\n",
    "# Remove standards \n",
    "input_file_df = input_file_df[input_file_df[\"Content\"].str.contains(\"Standard\") == False]\n",
    "input_file_df = input_file_df.reset_index(drop=True)\n",
    "\n",
    "# Remove samples with negative concentrations and add to output report\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    if Concentration <= 0:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Sample has negative value for concentration\"}, ignore_index=True)\n",
    "        input_file_df = input_file_df.drop(Index)\n",
    "\n",
    "input_file_df = input_file_df.reset_index(drop=True)\n",
    "output_report_df = output_report_df.reset_index(drop=True)\n",
    "\n",
    "# Copy trimmed input file into the output folder\n",
    "input_file_df.to_csv(output_files_folder + \"InputFiles/\" + \"InputTrimmedFile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "d0c95a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Weights \n",
    "\n",
    "max_concentration = input_file_df['Concentration'].max()\n",
    "sum_weights = float()\n",
    "\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "\n",
    "    sample_weight = max_concentration/Concentration\n",
    "    sum_weights += sample_weight\n",
    "    output_file_df = output_file_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Sample Calculated Weight': sample_weight}, ignore_index=True)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "ece0ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalised Weights \n",
    "\n",
    "sum_normalised_weights = float(0)\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    sample_normalised_weight = output_file_df[\"Sample Calculated Weight\"].iloc[Index]/sum_weights\n",
    "    sum_normalised_weights += sample_normalised_weight # for QC, should be =1\n",
    "    output_file_df.at[Index,'Sample Calculated Weight Normalised']=sample_normalised_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "a3ba5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Volume to pipette for each sample in the final pool\n",
    "\n",
    "vol_in_pool = float()\n",
    "sum_vol_in_pool = float(0)\n",
    "fail_bool = bool(0)\n",
    "\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    vol_in_pool = output_file_df[\"Sample Calculated Weight Normalised\"].iloc[Index]*final_pool_vol \n",
    "    sum_vol_in_pool += vol_in_pool # for QC, should be = final_pool_vol  \n",
    "    \n",
    "    if vol_in_pool < min_pipetting_capacity:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Volume to be pipetted for this well ({} nL) is smaller than pipetting capacity ({} nL). You MUST reprocess the file\".format(vol_in_pool,min_pipetting_capacity)}, ignore_index=True)\n",
    "        fail_bool = bool(1)\n",
    "    elif vol_in_pool > vol_available_in_well:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Volume to be pipetted for this well ({} nL) is larger than the volume available ({} nL). You MUST reprocess the file\".format(vol_in_pool,vol_available_in_well)}, ignore_index=True)\n",
    "        fail_bool = bool(1)\n",
    "    else:\n",
    "        output_file_df.at[Index,'Sample Calculated Volume In Pool']=vol_in_pool\n",
    "        if BeckmanOrEcho == \"Echo\":\n",
    "            output_echo_file_df = output_echo_file_df.append({'Source Well': Well, 'Destination Well': pool_well_in_output_plate, 'Transfer Volume': vol_in_pool}, ignore_index=True)\n",
    "        elif BeckmanOrEcho == \"Beckman\":\n",
    "            output_beckman_file_df = output_beckman_file_df.append({'Source Well': Well, 'Destination Well': pool_well_in_output_plate, 'Transfer Volume': vol_in_pool}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "d74c3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final pool concentration for QC \n",
    "\n",
    "sum_concentrations = float(0)\n",
    "\n",
    "for row in output_file_df.itertuples():\n",
    "    \n",
    "    Concentration = row[2]\n",
    "    VolInPool = row[5]\n",
    "    \n",
    "    sum_concentrations += (Concentration*VolInPool)\n",
    "\n",
    "final_pool_concentration = \"%.3f\"%(sum_concentrations / final_pool_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "0512a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export files and communicate outcome to user in GUI\n",
    "\n",
    "os.mkdir(output_files_folder + \"OutputFiles/\")\n",
    "\n",
    "if BeckmanOrEcho == \"Echo\":\n",
    "    if fail_bool == bool(1):\n",
    "        layout = [[sg.Text(\"Processing failed. The concentration of 1 sample or more is out of range and doesn't allow pooling with the settings entered. Check report file for details.\")], [sg.Button(\"OK\")]]\n",
    "        window = sg.Window(\"Echo File Generator For NGS Pooling\", layout)\n",
    "    else:\n",
    "        output_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_file_name, index=False)\n",
    "        output_echo_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_echo_file_name, index=False)\n",
    "        layout = [[sg.Text(\"Processing successful! Final pool concentration: {} ng/uL.\".format(final_pool_concentration))], [sg.Button(\"OK\")]]\n",
    "        window = sg.Window(\"Echo File Generator For NGS Pooling\", layout)\n",
    "\n",
    "elif BeckmanOrEcho == \"Beckman\":\n",
    "    if fail_bool == bool(1):\n",
    "        layout = [[sg.Text(\"Processing failed. The concentration of 1 sample or more is out of range and doesn't allow pooling with the settings entered. Check report file for details.\")], [sg.Button(\"OK\")]]\n",
    "        window = sg.Window(\"Beckman File Generator For NGS Pooling\", layout)\n",
    "    else:\n",
    "        output_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_file_name, index=False)\n",
    "        output_beckman_file_df = output_beckman_file_df.sort_values(by='Transfer Volume', ascending=False)\n",
    "        output_beckman_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_beckman_file_name, index=False)\n",
    "        layout = [[sg.Text(\"Processing successful! Final pool concentration: {} ng/uL.\".format(final_pool_concentration))], [sg.Button(\"OK\")]]\n",
    "        window = sg.Window(\"Beckman File Generator For NGS Pooling\", layout)\n",
    "    \n",
    "\n",
    "output_report_df.to_csv(output_files_folder + \"OutputFiles/\" + output_report_name, index=False)\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event == \"OK\" or event == sg.WIN_CLOSED:\n",
    "        break\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e0a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
